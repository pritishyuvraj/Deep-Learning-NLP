{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from pprint import pprint \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = \"\"\"\n",
    "I study at University of Massachusetts Amherst. \n",
    "I love staying here. Its fun here. \n",
    "It is quite cold out here. But I love this weather. \n",
    "I wish I could be pursuing my UnderGrad here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(X, Y):\n",
    "    for i, j in zip(X, Y):\n",
    "        print i, Y[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'study', 'at', 'university', 'of', 'massachusetts', 'amherst'] 1\n",
      "['i', 'love', 'staying', 'here'] 2\n",
      "['its', 'fun', 'here'] 2\n",
      "['it', 'is', 'quite', 'cold', 'out', 'here'] 0\n",
      "['but', 'i', 'love', 'this', 'weather'] 2\n",
      "['i', 'wish', 'i', 'could', 'be', 'pursuing', 'my', 'undergrad', 'here'] 1\n"
     ]
    }
   ],
   "source": [
    "X = [x for x in Data.strip().split('.') if x != '']\n",
    "Y = {}\n",
    "#RegEx\n",
    "import re \n",
    "for index, sentence in enumerate(X):\n",
    "    X[index], Y[index] = re.findall(r\"\\w+\", sentence.lower()), 0\n",
    "#print (X, Y)\n",
    "Y[0] = 1\n",
    "Y[1] = 2\n",
    "Y[2] = 2\n",
    "Y[3] = 0\n",
    "Y[4] = 2\n",
    "Y[5] = 1\n",
    "display(X, Y)\n",
    "sentence_x, sentiment_y = X, Y\n",
    "#0: negative\n",
    "#1: Neutral\n",
    "#2: Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Padding \n",
    "length = 10\n",
    "for sent_index, sentence in enumerate(sentence_x):\n",
    "    if len(sentence)<10:\n",
    "        #Padding\n",
    "        sentence_x[sent_index] += [\"<pad>\" for x in xrange(len(sentence), length)]\n",
    "    else:\n",
    "        sentence_x[sent_index] = sentence_x[sent_index][0:length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 10, 10]\n",
      "[['i', 'study', 'at', 'university', 'of', 'massachusetts', 'amherst', '<pad>', '<pad>', '<pad>'], ['i', 'love', 'staying', 'here', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['its', 'fun', 'here', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['it', 'is', 'quite', 'cold', 'out', 'here', '<pad>', '<pad>', '<pad>', '<pad>'], ['but', 'i', 'love', 'this', 'weather', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['i', 'wish', 'i', 'could', 'be', 'pursuing', 'my', 'undergrad', 'here', '<pad>']]\n"
     ]
    }
   ],
   "source": [
    "#Padding\n",
    "print ([len(sent) for sent in sentence_x])\n",
    "print sentence_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Unique Vocabulory\n",
    "word2index = {}\n",
    "count = 0\n",
    "for sentence in sentence_x:\n",
    "    for word in sentence:\n",
    "        if word not in word2index:\n",
    "            word2index[word] = count\n",
    "            count += 1 \n",
    "index2words = dict((v, k) for k, v in word2index.iteritems())\n",
    "#pprint(word2index)\n",
    "#pprint(index2words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6, 7, 7, 7], [0, 8, 9, 10, 7, 7, 7, 7, 7, 7], [11, 12, 10, 7, 7, 7, 7, 7, 7, 7], [13, 14, 15, 16, 17, 10, 7, 7, 7, 7], [18, 0, 8, 19, 20, 7, 7, 7, 7, 7], [0, 21, 0, 22, 23, 24, 25, 26, 10, 7]]\n"
     ]
    }
   ],
   "source": [
    "#Converting Words to indexes\n",
    "for sent_index, sent in enumerate(sentence_x):\n",
    "    for word_index, word in enumerate(sent):\n",
    "        sentence_x[sent_index][word_index] = word2index[sentence_x[sent_index][word_index]]\n",
    "print sentence_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "def one_hot_2D(array, list_length):\n",
    "    for index_i, sentence in enumerate(array):\n",
    "        for index_j, word in enumerate(sentence):\n",
    "            temp = [0 for x in xrange(list_length)]\n",
    "            temp[array[index_i][index_j]] = 1\n",
    "            array[index_i][index_j] = temp\n",
    "    return array\n",
    "train_x = one_hot_2D(sentence_x, len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_1D(array, list_length):\n",
    "    return_array = []\n",
    "    for index_i, indices in enumerate(array):\n",
    "        temp = [0 for x in xrange(list_length)]\n",
    "        temp[array[indices]] = 1\n",
    "        return_array.append(temp)\n",
    "    return return_array\n",
    "train_y = one_hot_1D(sentiment_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 10 27\n",
      "(6, 10, 27) (6, 3)\n"
     ]
    }
   ],
   "source": [
    "print len(train_x), len(train_x[0]), len(train_x[0][0])\n",
    "x1 = np.asarray(train_x)\n",
    "y1 = np.asarray(train_y)\n",
    "'''for i in xrange(len(train_x)):\n",
    "    for j in xrange(len(train_x[i])):\n",
    "        for k in xrange(len(train_x[i][j])):\n",
    "            pass\n",
    "        #print i, j, k'''\n",
    "print x1.shape, y1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Network parameters \n",
    "num_input = 28\n",
    "timesteps = 28\n",
    "num_hidden = 128\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
