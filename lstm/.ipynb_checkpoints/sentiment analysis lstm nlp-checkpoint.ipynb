{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Pritish Yuvraj\n",
    "#### Sentiment Analysis using Deep Learning\n",
    "#### Natural Language Processing (NLP) using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from pprint import pprint \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = \"\"\"\n",
    "I study at University of Massachusetts Amherst. \n",
    "I love staying here. Its fun here. \n",
    "It is quite cold out here. But I love this weather. \n",
    "I wish I could be pursuing my UnderGrad here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(X, Y):\n",
    "    for i, j in zip(X, Y):\n",
    "        print i, Y[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'study', 'at', 'university', 'of', 'massachusetts', 'amherst'] 1\n",
      "['i', 'love', 'staying', 'here'] 2\n",
      "['its', 'fun', 'here'] 2\n",
      "['it', 'is', 'quite', 'cold', 'out', 'here'] 0\n",
      "['but', 'i', 'love', 'this', 'weather'] 2\n",
      "['i', 'wish', 'i', 'could', 'be', 'pursuing', 'my', 'undergrad', 'here'] 1\n"
     ]
    }
   ],
   "source": [
    "X = [x for x in Data.strip().split('.') if x != '']\n",
    "Y = {}\n",
    "#RegEx\n",
    "import re \n",
    "for index, sentence in enumerate(X):\n",
    "    X[index], Y[index] = re.findall(r\"\\w+\", sentence.lower()), 0\n",
    "#print (X, Y)\n",
    "Y[0] = 1\n",
    "Y[1] = 2\n",
    "Y[2] = 2\n",
    "Y[3] = 0\n",
    "Y[4] = 2\n",
    "Y[5] = 1\n",
    "display(X, Y)\n",
    "sentence_x, sentiment_y = X, Y\n",
    "#0: negative\n",
    "#1: Neutral\n",
    "#2: Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Padding \n",
    "length = 10\n",
    "for sent_index, sentence in enumerate(sentence_x):\n",
    "    if len(sentence)<10:\n",
    "        #Padding\n",
    "        sentence_x[sent_index] += [\"<pad>\" for x in xrange(len(sentence), length)]\n",
    "    else:\n",
    "        sentence_x[sent_index] = sentence_x[sent_index][0:length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 10, 10]\n",
      "[['i', 'study', 'at', 'university', 'of', 'massachusetts', 'amherst', '<pad>', '<pad>', '<pad>'], ['i', 'love', 'staying', 'here', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['its', 'fun', 'here', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['it', 'is', 'quite', 'cold', 'out', 'here', '<pad>', '<pad>', '<pad>', '<pad>'], ['but', 'i', 'love', 'this', 'weather', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['i', 'wish', 'i', 'could', 'be', 'pursuing', 'my', 'undergrad', 'here', '<pad>']]\n"
     ]
    }
   ],
   "source": [
    "#Padding\n",
    "print ([len(sent) for sent in sentence_x])\n",
    "print sentence_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding Unique Vocabulory\n",
    "word2index = {}\n",
    "count = 0\n",
    "for sentence in sentence_x:\n",
    "    for word in sentence:\n",
    "        if word not in word2index:\n",
    "            word2index[word] = count\n",
    "            count += 1 \n",
    "index2words = dict((v, k) for k, v in word2index.iteritems())\n",
    "#pprint(word2index)\n",
    "#pprint(index2words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6, 7, 7, 7], [0, 8, 9, 10, 7, 7, 7, 7, 7, 7], [11, 12, 10, 7, 7, 7, 7, 7, 7, 7], [13, 14, 15, 16, 17, 10, 7, 7, 7, 7], [18, 0, 8, 19, 20, 7, 7, 7, 7, 7], [0, 21, 0, 22, 23, 24, 25, 26, 10, 7]]\n"
     ]
    }
   ],
   "source": [
    "#Converting Words to indexes\n",
    "for sent_index, sent in enumerate(sentence_x):\n",
    "    for word_index, word in enumerate(sent):\n",
    "        sentence_x[sent_index][word_index] = word2index[sentence_x[sent_index][word_index]]\n",
    "print sentence_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "def one_hot_2D(array, list_length):\n",
    "    for index_i, sentence in enumerate(array):\n",
    "        for index_j, word in enumerate(sentence):\n",
    "            temp = [0 for x in xrange(list_length)]\n",
    "            temp[array[index_i][index_j]] = 1\n",
    "            array[index_i][index_j] = temp\n",
    "    return array\n",
    "train_x = one_hot_2D(sentence_x, len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_1D(array, list_length):\n",
    "    return_array = []\n",
    "    for index_i, indices in enumerate(array):\n",
    "        temp = [0 for x in xrange(list_length)]\n",
    "        temp[array[indices]] = 1\n",
    "        return_array.append(temp)\n",
    "    return return_array\n",
    "train_y = one_hot_1D(sentiment_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 10, 27) (6, 3)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "'''for i in xrange(len(train_x)):\n",
    "    for j in xrange(len(train_x[i])):\n",
    "        for k in xrange(len(train_x[i][j])):\n",
    "            pass\n",
    "        #print i, j, k'''\n",
    "print train_x.shape, train_y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Network parameters \n",
    "num_input = train_x.shape[2]\n",
    "timesteps = train_x.shape[1]\n",
    "num_hidden = 128\n",
    "num_classes = train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 1.2209, Training Accuracy= 0.500\n",
      "Step 200, Minibatch Loss= 0.7177, Training Accuracy= 0.667\n",
      "Step 400, Minibatch Loss= 0.5367, Training Accuracy= 0.833\n",
      "Step 600, Minibatch Loss= 0.4097, Training Accuracy= 0.833\n",
      "Step 800, Minibatch Loss= 0.3137, Training Accuracy= 1.000\n",
      "Step 1000, Minibatch Loss= 0.2399, Training Accuracy= 1.000\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: train_x, Y: train_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_x,\n",
    "                                                                 Y: train_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
